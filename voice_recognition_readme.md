# Live2D AI助手 - 语音识别功能

本文档介绍了Live2D AI助手新增的语音识别功能，包括安装、配置和使用方法。

## 功能概述

语音识别功能允许用户通过语音与Live2D虚拟角色进行交互，支持两种识别模式：

1. **服务器模式**：使用OpenAI的Whisper模型进行高精度语音识别
2. **浏览器模式**：使用Web Speech API进行低延迟语音识别

## 安装依赖

语音识别功能需要额外的Python依赖，请确保安装以下包：

```bash
pip install torch==2.1.0 transformers==4.35.0 librosa==0.10.1 numpy==1.24.3 soundfile==0.12.1
```

或者直接使用更新后的requirements.txt文件：

```bash
pip install -r requirements.txt
```

## 使用方法

### 1. 启动服务器

确保安装了所有依赖后，启动服务器：

```bash
python server.py
```

首次启动时，系统会自动下载Whisper模型（约1GB），请保持网络连接。

### 2. 使用语音输入

在Web界面中：

1. 点击输入框旁边的麦克风按钮 🎤 开始录音
2. 说出您想问的问题
3. 再次点击麦克风按钮或等待自动停止录音
4. 系统会自动识别您的语音并填入输入框
5. 如果启用了"自动发送"选项，系统会自动发送识别结果

### 3. 配置语音识别

在"语音设置"标签页中，切换到"语音识别"选项卡，可以进行以下设置：

- **启用语音识别**：开启或关闭语音识别功能
- **识别模式**：
  - 服务器模式：使用Whisper模型，精度高但有网络延迟
  - 浏览器模式：使用Web Speech API，延迟低但精度可能较低
- **语言**：选择中文或英语
- **自动发送**：识别完成后是否自动发送消息

## 技术说明

### 服务器模式

服务器模式使用OpenAI的Whisper模型进行语音识别，具有以下特点：

- 高精度识别，支持多种语言和方言
- 需要服务器资源进行处理
- 首次使用时需要下载模型
- 适合需要高精度识别的场景

### 浏览器模式

浏览器模式使用Web Speech API进行语音识别，具有以下特点：

- 低延迟，实时反馈
- 不消耗服务器资源
- 依赖浏览器支持，不同浏览器效果可能不同
- 适合需要快速响应的场景

## 故障排除

1. **无法访问麦克风**
   - 确保已授予浏览器麦克风访问权限
   - 检查麦克风是否正常工作
   - 尝试刷新页面或重启浏览器

2. **服务器模式不工作**
   - 确保已安装所有必要的依赖
   - 检查网络连接是否正常
   - 查看服务器日志是否有错误信息

3. **浏览器模式不工作**
   - 确认您的浏览器支持Web Speech API（Chrome、Edge等现代浏览器支持）
   - 系统会自动切换到服务器模式作为备选方案

4. **识别准确率低**
   - 尝试在安静的环境中使用
   - 说话清晰，避免背景噪音
   - 对于中文识别，服务器模式通常比浏览器模式更准确

## 已知限制

1. 服务器模式首次使用时需要下载模型，可能需要一些时间
2. 浏览器模式在某些浏览器中可能不可用
3. 长时间录音可能会导致性能问题
4. 某些方言或口音的识别准确率可能较低

## 未来计划

1. 添加更多语言支持
2. 优化模型大小和加载速度
3. 实现完全客户端的语音识别（使用WebAssembly版Whisper）
4. 添加噪音过滤和语音增强功能
