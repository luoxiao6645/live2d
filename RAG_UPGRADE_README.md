# Live2D AI助手 RAG功能升级指南

## 🎯 升级概述

本次升级为Live2D AI助手添加了强大的RAG（检索增强生成）功能，让AI助手能够基于您上传的文档内容提供更准确、更相关的回答。

## ✨ 新增功能

### 📚 知识库管理
- **文档上传**：支持PDF、DOCX、DOC、TXT、Markdown格式
- **智能分块**：自动将文档分割为语义完整的片段
- **向量存储**：使用Chroma向量数据库进行高效存储和检索
- **文档管理**：查看、搜索、删除已上传的文档

### 🤖 RAG增强对话
- **智能检索**：根据用户问题自动检索相关文档片段
- **上下文增强**：将检索到的内容作为上下文提供给AI模型
- **来源追踪**：显示回答所参考的文档来源
- **模式切换**：可在普通对话和RAG增强对话间切换

### 🔧 技术特性
- **LangChain集成**：使用业界领先的LLM应用框架
- **多格式支持**：智能识别和处理多种文档格式
- **流式响应**：保持原有的实时对话体验
- **错误处理**：完善的错误处理和降级机制

## 🚀 安装和使用

### 1. 安装依赖

#### 方法一：使用安装脚本（推荐）
```bash
python install_rag_dependencies.py
```

#### 方法二：手动安装
```bash
pip install -r requirements.txt
```

### 2. 启动服务
```bash
python server.py
```

### 3. 使用RAG功能

1. **启用RAG功能**
   - 在控制面板中找到"📚 知识库管理"部分
   - 勾选"启用RAG增强对话"

2. **上传文档**
   - 点击"选择文件"按钮选择文档
   - 支持的格式：PDF、DOCX、DOC、TXT、MD
   - 点击"上传"按钮开始处理

3. **开始对话**
   - 上传文档后，AI助手会基于文档内容回答问题
   - 系统会显示参考的文档片段
   - 可以随时切换回普通对话模式

## 📋 API接口

### RAG状态检查
```
GET /api/rag/status
```

### 文档上传
```
POST /api/rag/upload
Content-Type: multipart/form-data
Body: file=<文档文件>
```

### 知识库信息
```
GET /api/rag/knowledge_base
```

### 文档搜索
```
POST /api/rag/search
Content-Type: application/json
Body: {"query": "搜索内容", "k": 5}
```

### RAG增强对话
```
POST /rag_generate
Content-Type: application/json
Body: {
  "prompt": "用户问题",
  "use_rag": true,
  "model_name": "qwen2:0.5b",
  "temperature": 0.7
}
```

## 🔧 配置说明

### 环境变量
- `OLLAMA_API_URL`: Ollama服务地址（默认：http://127.0.0.1:11434）

### 文件路径
- `./knowledge_base/`: 向量数据库存储目录
- `./uploads/`: 上传文档临时存储目录

### 模型配置
- **嵌入模型**: sentence-transformers/all-MiniLM-L6-v2
- **向量数据库**: Chroma
- **文本分块**: RecursiveCharacterTextSplitter (chunk_size=1000, overlap=200)

## 🛠️ 故障排除

### 常见问题

1. **RAG功能不可用**
   - 检查是否正确安装了所有依赖
   - 运行 `python install_rag_dependencies.py` 重新安装

2. **文档上传失败**
   - 检查文件格式是否支持
   - 确认文件大小不超过50MB
   - 检查uploads目录权限

3. **向量数据库错误**
   - 删除 `./knowledge_base/` 目录重新初始化
   - 检查磁盘空间是否充足

4. **嵌入模型下载慢**
   - 首次使用会自动下载模型，请耐心等待
   - 可以手动下载模型到本地缓存目录

### 日志查看
服务器日志会显示详细的错误信息，包括：
- RAG模块加载状态
- 文档处理进度
- 向量数据库操作
- 检索和生成过程

## 📊 性能优化

### 建议配置
- **内存**: 建议8GB以上
- **存储**: SSD硬盘，至少5GB可用空间
- **CPU**: 多核处理器，支持向量计算

### 优化建议
1. **文档预处理**: 上传前清理文档格式，移除无关内容
2. **分块策略**: 根据文档类型调整分块大小
3. **检索参数**: 根据需要调整检索结果数量(k值)
4. **模型选择**: 根据硬件配置选择合适的嵌入模型

## 🔄 版本兼容性

### 保持兼容的功能
- ✅ Live2D模型展示
- ✅ 语音合成和口型同步
- ✅ 语音识别
- ✅ 情感表达系统
- ✅ 背景设置
- ✅ 普通AI对话

### 新增功能
- 🆕 RAG增强对话
- 🆕 知识库管理
- 🆕 文档上传和处理
- 🆕 向量检索
- 🆕 LangChain集成

## 📞 技术支持

如果在使用过程中遇到问题，请：

1. 查看服务器日志输出
2. 检查依赖安装是否完整
3. 确认Ollama服务正常运行
4. 参考本文档的故障排除部分

## 🎉 总结

RAG功能的加入让Live2D AI助手具备了基于文档的智能问答能力，大大提升了实用性。您可以上传各种文档，让AI助手成为您的专属知识库助手，同时保持原有的可爱Live2D形象和自然的交互体验。

享受您的智能AI助手吧！ 🎭✨
